# Teste T√©cnico: Pipeline de Ingest√£o Peri√≥dica + API + Dashboard

Para visualizar o arquivo formatado, utilizar um visualizador de Markdown.

## Contexto

Na Driva, trabalhamos com intelig√™ncia de mercado B2B atrav√©s do nosso principal produto: o **HubDriva**. Uma das funcionalidades mais importantes da plataforma √© o **Enriquecimento de Dados**, que permite aos nossos clientes (workspaces) agregarem informa√ß√µes valiosas a dados de empresas brasileiras.

**Como funciona o Enriquecimento:**

- Workspaces utilizam cr√©ditos para executar jobs de enriquecimento
- Cada job processa um conjunto de empresas/pessoas, agregando dados como e-mails, telefones, informa√ß√µes corporativas, etc.
- Os workspaces consomem esses dados enriquecidos para suas estrat√©gias de vendas e marketing

**O Problema:**

O time de **Visibilidade** precisa monitorar a performance e qualidade dos enriquecimentos que est√£o sendo entregues na plataforma. Para isso, √© necess√°rio:

- Ter visibilidade sobre quantos enriquecimentos est√£o sendo realizados
- Analisar o desempenho (tempo de processamento, taxa de sucesso/falha)
- Identificar padr√µes e problemas
- Gerar insights para melhorias

**Sua Miss√£o:**

Como membro do **time de Tech**, voc√™ foi designado para construir uma pipeline de dados que consulte periodicamente uma API interna que retorna informa√ß√µes sobre os enriquecimentos realizados na plataforma. Os dados devem ser processados e armazenados seguindo uma arquitetura de data warehouse em camadas **Bronze** (dados brutos) e **Gold** (dados processados e prontos para an√°lise).

Al√©m disso, voc√™ dever√° disponibilizar esses dados por meio de uma **API** e construir um **dashboard simples** (frontend) para consumo do time de Visibilidade.

## Objetivo da solu√ß√£o

1. Subir um ambiente local com Docker contendo **PostgreSQL**, **n8n**, **API** e (opcionalmente) o **frontend**
2. Construir uma **API** que:
   - Exponha um endpoint paginado simulando a API de enriquecimentos
   - Exponha endpoints de leitura/consulta sobre a camada Gold para o dashboard
3. Coletar dados de enriquecimentos (via n8n) **com um pooling de 5 minutos**
4. Armazenar os dados brutos na camada **Bronze**
5. Processar, validar e transformar os dados na camada **Gold**
6. Criar um **dashboard simples** que mostre m√©tricas e listas relevantes (consumindo a API)

---

## O Desafio

Seu desafio √© construir e orquestrar um ambiente local com Docker, implementar uma API e criar workflows no **n8n** para ingest√£o e processamento peri√≥dico.

O desafio √© dividido em **quatro etapas**:

1. **Configurar o Ambiente:** Usar **Docker** para subir as inst√¢ncias do PostgreSQL, n8n e a API, incluindo a inicializa√ß√£o autom√°tica das tabelas do banco de dados.
2. **Construir a API:** Implementar endpoints que simulam a fonte (enrichments) e exp√µem dados anal√≠ticos da camada Gold.
3. **Workflows no n8n (Bronze + Gold):** Criar workflows de ingest√£o e processamento (cham√°veis) e um workflow orquestrador (agendado a cada 5 minutos).
4. **Dashboard (Frontend):** Criar um dashboard simples (tecnologia de frontend √† sua escolha) consumindo a API.

> **Observa√ß√£o:** Pense em como os workflows devem ser estruturados e acionados para garantir que o pipeline completo seja executado periodicamente de forma eficiente e organizada.

---

## Recursos Fornecidos

### 1) Arquitetura Local (Docker)

Voc√™ deve criar um arquivo `docker-compose.yml` para orquestrar os servi√ßos.

**‚ö†Ô∏è OBRIGAT√ìRIO:** O `docker-compose.yml` deve incluir um volume que monte um arquivo `init.sql` para criar automaticamente todas as tabelas necess√°rias quando o PostgreSQL subir pela primeira vez.

**Servi√ßos m√≠nimos obrigat√≥rios:**

- **Servi√ßo 1: `postgres`**

  - Use uma imagem oficial do PostgreSQL (vers√£o 14 ou superior)
  - Configure as vari√°veis de ambiente necess√°rias (usu√°rio, senha, database)
  - Monte um script `init.sql` para cria√ß√£o das tabelas
  - Exponha a porta padr√£o (5432)

- **Servi√ßo 2: `n8n`**

  - Use a imagem oficial do n8n
  - Deve rodar localmente (ex: `http://localhost:5678`)
  - Configure para persistir os workflows
  - Deve conseguir se conectar ao PostgreSQL

- **Servi√ßo 3: `api`**

  - Linguagem/framework livre (ex.: Node/Nest/Express, Go, Python/FastAPI)
  - Deve rodar localmente (ex.: `http://localhost:3000`)
  - Deve conseguir se conectar ao PostgreSQL
  - Deve implementar os endpoints descritos na se√ß√£o **API**

- **Servi√ßo 4: `frontend`**
  - Subir o frontend via Docker (opcional), **ou**
  - Executar fora do Docker (ex.: Vite/Next) e documentar no README.
  - O importante √©: o dashboard **funcionar** e consumir a API.

---

### 2) API (voc√™ deve construir)

A API ter√° **dois grupos de endpoints**:

1. **Fonte (simula√ß√£o da API de enriquecimentos)** ‚Äì consumida pelo n8n
2. **Analytics (leitura da camada Gold)** ‚Äì consumida pelo dashboard

#### 2.1) Autentica√ß√£o

- A API requer autentica√ß√£o via **API Key**
- Header: `Authorization: Bearer {API_KEY}`
- API Key (para o teste): `driva_test_key_abc123xyz789`

#### 2.2) Endpoint de Fonte (para ingest√£o)

**Endpoint:** `GET /v1/enrichments`

**Query Parameters (Pagina√ß√£o):**

- `page` (int): N√∫mero da p√°gina atual (default: 1)
- `limit` (int): Itens por p√°gina (default: 50, max: 100)

**‚ö†Ô∏è IMPORTANTE ‚Äì PAGINA√á√ÉO E RATE LIMITING:**

- A API deve ter **milhares de registros** (pode gerar em runtime ou seedar via SQL/arquivo JSON).
- A resposta deve incluir `meta.total_pages`, `meta.total_items`, etc.
- A API **pode retornar** `429 Too Many Requests` (simula√ß√£o) ‚Äî por exemplo, em bursts ou aleatoriamente.

**Estrutura da Resposta (JSON):**

```json
{
  "meta": {
    "current_page": 1,
    "items_per_page": 50,
    "total_items": 5000,
    "total_pages": 100
  },
  "data": [
    {
      "id": "f47ac10b-58cc-4372-a567-0e02b2c3d479",
      "id_workspace": "e6bb64bf-46e4-410d-8406-c61e267ea607",
      "workspace_name": "Tech Solutions Corp",
      "total_contacts": 1500,
      "contact_type": "COMPANY",
      "status": "COMPLETED",
      "created_at": "2025-11-15T14:30:00Z",
      "updated_at": "2025-11-15T14:35:22Z"
    }
  ]
}
```

> **Dica:** voc√™ pode armazenar esses enrichments em uma tabela no Postgres (seed) e apenas paginar via SQL. Isso facilita testar, manter determinismo e validar o pipeline.

#### 2.3) Endpoints de Analytics (para dashboard)

Voc√™ deve criar endpoints para leitura da camada Gold. Sugest√£o m√≠nima:

- `GET /analytics/overview`
  - Retorna KPIs para o dashboard (ex.: total de jobs, % sucesso, tempo m√©dio, distribui√ß√£o por categoria)
- `GET /analytics/enrichments`
  - Lista paginada/filtr√°vel (ex.: por `id_workspace`, `status_processamento`, per√≠odo)
- (B√¥nus) `GET /analytics/workspaces/top`
  - Ranking de workspaces por volume de enriquecimentos ou total_contatos

**Requisitos gerais:**

- Os endpoints devem consultar a camada Gold no Postgres.
- Devem ser r√°pidos e bem estruturados (pode usar √≠ndices).
- Devem devolver JSON simples (sem necessidade de autentica√ß√£o extra al√©m da API Key).

---

### 3) Regras de Neg√≥cio (Bronze e Gold)

#### Camada Bronze

- Deve armazenar **todos os dados de enriquecimento** retornados pela API
- Cada registro de enriquecimento deve ser armazenado individualmente
- Deve permitir rastreamento de quando cada job foi ingerido no DW
- Caso um registro j√° esteja no banco de dados, atualizar os dados
- **Campos obrigat√≥rios de controle do DW:**
  - `dw_ingested_at` (TIMESTAMP): data/hora em que o registro foi ingerido pela primeira vez na Bronze
  - `dw_updated_at` (TIMESTAMP): data/hora da √∫ltima atualiza√ß√£o do registro na Bronze
- **Dica de modelagem:** Na Bronze, priorize captura fiel. Considere tipos flex√≠veis (ex.: `TEXT`/`JSONB`) para evitar falhas por incompatibilidade.

#### Camada Gold

- Deve processar apenas registros da Bronze que ainda n√£o foram processados (ou garantir que a Gold reflita o estado mais atual)
- **Todos os nomes de colunas e valores devem estar em portugu√™s**
- **Tradu√ß√£o de nomes de colunas (exemplos):**

  - `id` ‚Üí `id_enriquecimento`
  - `id_workspace` ‚Üí `id_workspace` (manter)
  - `workspace_name` ‚Üí `nome_workspace`
  - `total_contacts` ‚Üí `total_contatos`
  - `contact_type` ‚Üí `tipo_contato`
  - `status` ‚Üí `status_processamento`
  - `created_at` ‚Üí `data_criacao`
  - `updated_at` ‚Üí `data_atualizacao`

- **Criar novos campos calculados/transformados (aplicar):**
  - `duracao_processamento_minutos` (INTEGER/FLOAT): diferen√ßa em minutos entre `data_atualizacao` e `data_criacao`
  - `tempo_por_contato_minutos` (FLOAT): `duracao_processamento_minutos / total_contatos`
  - `processamento_sucesso` (BOOLEAN): `true` se `status_processamento = "CONCLUIDO"`
  - `categoria_tamanho_job` (VARCHAR): por `total_contatos`:
    - PEQUENO: < 100
    - MEDIO: 100-500
    - GRANDE: 501-1000
    - MUITO_GRANDE: > 1000
  - Traduzir valores de `tipo_contato`:
    - "PERSON" ‚Üí "PESSOA"
    - "COMPANY" ‚Üí "EMPRESA"
  - Traduzir valores de `status_processamento`:
    - "PROCESSING" ‚Üí "EM_PROCESSAMENTO"
    - "COMPLETED" ‚Üí "CONCLUIDO"
    - "FAILED" ‚Üí "FALHOU"
    - "CANCELED" ‚Üí "CANCELADO"
  - `necessita_reprocessamento` (BOOLEAN): `true` se status original = "FAILED" ou "CANCELED"
  - **Campo obrigat√≥rio:** `data_atualizacao_dw` (TIMESTAMP): data/hora da execu√ß√£o do processamento (snapshot)

---

## 4) Estrutura das Tabelas (init.sql)

Voc√™ deve criar um arquivo **`init.sql`** com as defini√ß√µes de todas as tabelas necess√°rias para o projeto.

---

## Requisitos dos Workflows (n8n)

### Workflow de Ingest√£o (API ‚Üí Bronze) ‚Äî **cham√°vel**

Este workflow deve:

1. Tratar pagina√ß√£o e buscar **todas as p√°ginas** a cada execu√ß√£o (ou aplicar estrat√©gia de watermark/atualiza√ß√£o incremental ‚Äî se fizer, documente).
2. Fazer requisi√ß√£o HTTP para a **sua API local**:
   - `GET http://api:3000/v1/enrichments?page={page}&limit=50` (dentro do Docker)
   - `Authorization: Bearer driva_test_key_abc123xyz789`
3. Tratar erros:
   - **429 Too Many Requests** (implementar retry com backoff)
4. Salvar na Bronze:
   - Insert/Upsert de todos os campos do enrichment
   - Preencher `dw_ingested_at` (na primeira ingest√£o) e `dw_updated_at` (em toda atualiza√ß√£o)
   - Registrar p√°gina/execu√ß√£o (como preferir)

### Workflow de Processamento (Bronze ‚Üí Gold) ‚Äî **cham√°vel**

Este workflow deve:

1. Ler registros da Bronze e aplicar as transforma√ß√µes definidas
2. Popular a Gold garantindo:
   - colunas/valores em portugu√™s
   - campos calculados preenchidos
   - `data_atualizacao_dw` preenchido
3. Garantir que a Gold reflita o estado mais atual da Bronze (upsert/snapshot/merge ‚Äî escolha e documente)

### Workflow Orquestrador (Scheduler) ‚Äî **agendado a cada 5 minutos**

Voc√™ deve criar um workflow no n8n que:

1. Rode a cada **5 minutos**
2. Chame o workflow de ingest√£o
3. Ao finalizar, chame o workflow de processamento
4. Fa√ßa logging/observabilidade m√≠nima (ex.: status, n√∫mero de registros, erros)

---

## 5) Dashboard (Frontend)

Ap√≥s a pipeline estar funcionando, voc√™ deve construir um **dashboard simples** que consuma os endpoints de **Analytics** da sua API.

**Requisitos m√≠nimos do dashboard:**

- Uma p√°gina principal com KPIs (ex.: total de enriquecimentos, % sucesso, tempo m√©dio de processamento)
- Um gr√°fico simples **ou** tabela resumida (ex.: distribui√ß√£o por `categoria_tamanho_job` ou por `status_processamento`)
- Uma lista/tabela paginada (ou com filtro) de enriquecimentos

**Tecnologia livre**, por exemplo:

- React + Vite, Next.js, Vue, Svelte, Angular, etc.

> O objetivo √© avaliar a capacidade de integrar ponta-a-ponta: DW + automa√ß√£o + API + visualiza√ß√£o.

---

## Crit√©rios de Avalia√ß√£o

1. **Funcionalidade ponta-a-ponta:** API + n8n + DW + dashboard funcionando conforme especificado
2. **Modelagem de Dados:** tabelas bem projetadas (Bronze/Gold, √≠ndices, consist√™ncia)
3. **Qualidade da API:** endpoints bem definidos, pagina√ß√£o, autentica√ß√£o, boas pr√°ticas
4. **Qualidade dos Workflows:** organiza√ß√£o, legibilidade, modularidade, retry/backoff, logs
5. **Qualidade do Dashboard:** simplicidade, clareza, consumo correto da API, UX b√°sica
6. **Documenta√ß√£o:** README claro (como rodar tudo) + decis√µes registradas
7. **Boas Pr√°ticas:** tratamento de erro, estrutura do projeto

---

## Entreg√°veis

Para concluir o teste, voc√™ **DEVE** fornecer:

1. **Link do reposit√≥rio Git** (GitHub, GitLab, Bitbucket, etc.) contendo:
   - `docker-compose.yml`
   - `init.sql`
   - C√≥digo da API (com Dockerfile)
   - C√≥digo do Dashboard
   - JSONs dos Workflows exportados do n8n
   - `README.md` (principal) com:
     - vis√£o geral da solu√ß√£o
     - como subir o ambiente
     - como rodar o frontend (se fora do Docker)
     - como importar/executar workflows
     - exemplos de chamadas (curl) para os endpoints
2. **Link do v√≠deo de apresenta√ß√£o do projeto** com:
   - demonstra√ß√£o do ambiente funcionando (Docker, API, n8n, Dashboard)
   - explica√ß√£o da arquitetura da API e fluxo de dados
   - execu√ß√£o dos workflows e visualiza√ß√£o no dashboard
   - **demonstra√ß√£o de como voc√™ utilizou IA** (ex.: GitHub Copilot, ChatGPT, Claude, etc.) durante o desenvolvimento da solu√ß√£o

---

## Uso de Intelig√™ncia Artificial

**O uso de IA √© incentivado e encorajado!** Ferramentas como GitHub Copilot, ChatGPT, Claude, e outras podem acelerar seu desenvolvimento e melhorar a qualidade da solu√ß√£o.

**No v√≠deo de apresenta√ß√£o, voc√™ DEVE:**

- Mostrar exemplos concretos de como utilizou IA durante o projeto
- Explicar quais ferramentas utilizou e para quais tarefas (ex.: gera√ß√£o de c√≥digo, debugging, cria√ß√£o de queries SQL, design de API, etc.)
- Demonstrar o processo de itera√ß√£o com a IA (prompts, refinamentos, valida√ß√µes)
- Refletir sobre como a IA ajudou (ou n√£o) na resolu√ß√£o dos desafios

Queremos avaliar n√£o apenas a solu√ß√£o t√©cnica, mas tamb√©m sua capacidade de **usar IA de forma eficiente e cr√≠tica** no desenvolvimento de software.

---

Boa sorte! üöÄ
